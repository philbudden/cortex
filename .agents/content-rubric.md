# Content Evaluation Rubric

This file defines **criteria for evaluating content quality and long-term value** in this vault.

---

## Purpose

This rubric helps you (and AI assistants using the `review.md` and `scoring.md` skills) decide:

- What content is worth keeping
- What ideas merit development into atomic notes
- What sources are valuable enough to summarize
- What drafts are ready for further work

**This is a living document.** Customize it to match your interests, goals, and standards.

---

## How to Use This Rubric

### For Humans
- Review this rubric periodically
- Update criteria as your interests evolve
- Use it when deciding what to keep vs. archive

### For AI Assistants
- Read this rubric when performing content review or triage
- Apply these criteria when evaluating ideas, sources, or drafts
- Reference specific criteria when explaining recommendations

---

## Evaluation Framework

### Dimensions for All Content

#### 1. Clarity
**What it is:** How well-defined is the core idea?

- **Strong (3):** Central concept is immediately clear and concrete
- **Adequate (2):** Main idea is present but requires interpretation
- **Weak (1):** Unclear, scattered, or too vague to act on

**Why it matters:** Unclear ideas are hard to develop or connect to other work.

---

#### 2. Durability
**What it is:** Will this remain relevant and useful over time?

- **Strong (3):** Evergreen concept, foundational principle, or timeless insight
- **Adequate (2):** Contextual but extends beyond immediate circumstances
- **Weak (1):** Highly time-bound, ephemeral, or reactive

**Why it matters:** Your vault should accumulate lasting value, not clutter.

---

#### 3. Reusability
**What it is:** Can this idea be applied in multiple contexts?

- **Strong (3):** Broadly applicable pattern, framework, or mental model
- **Adequate (2):** Useful in specific domains or situations
- **Weak (1):** Single-use observation or context-specific note

**Why it matters:** Reusable ideas compound in value over time.

---

#### 4. Actionability
**What it is:** Does this enable or inform action?

- **Strong (3):** Direct implications for decisions, writing, or further research
- **Adequate (2):** Suggests possible directions or raises useful questions
- **Weak (1):** Interesting but inert; no clear next steps

**Why it matters:** Ideas that drive action are more valuable than passive observations.

---

#### 5. Uniqueness
**What it is:** Does this offer a perspective you can't easily find elsewhere?

- **Strong (3):** Original synthesis, counterintuitive insight, or personal experience
- **Adequate (2):** Useful framing of known ideas or well-curated evidence
- **Weak (1):** Common knowledge or easily rediscovered information

**Why it matters:** Your vault should capture what you uniquely think and know.

---

## Content-Specific Criteria

### For Ideas (from `00_Inbox/` or `01_Daily/`)

**Worth extracting to `02_Notes/` if:**
- Scores ≥2 on Clarity and Durability
- Represents a discrete, standalone concept
- Not already captured elsewhere in the vault

**Consider archiving if:**
- Scores ≤1 on Durability and Reusability
- Too vague or context-dependent to be useful later
- Duplicates existing notes without adding new insight

---

### For Sources (in `03_Research/`)

**Worth detailed summary if:**
- Scores ≥2 on Uniqueness and Actionability
- Directly informs active writing or thinking
- Contains evidence or arguments you'll reference repeatedly

**Consider brief capture if:**
- Scores 2 on Clarity and Durability but low on Uniqueness
- Useful for completeness but not central to your work
- Reference material you might need to cite

---

### For Writing Projects (in `04_Writing/`)

**Worth continuing if:**
- Scores ≥2 on Clarity, Actionability, and Uniqueness
- Thesis is defensible and interesting
- You have (or can develop) the evidence to support it

**Consider pausing if:**
- Scores ≤1 on Clarity (unclear what you're arguing)
- Scores ≤1 on Uniqueness (rehashing common points)
- No clear path forward or insufficient interest to complete

---

## Custom Criteria

*(Add your own evaluation dimensions here.)*

**Example structure:**

### [Custom Dimension Name]
**What it is:** [Brief definition]

- **Strong (3):** [Description]
- **Adequate (2):** [Description]  
- **Weak (1):** [Description]

**Why it matters:** [Rationale]

---

## Domain-Specific Filters

*(Optional: Add criteria specific to your areas of interest.)*

**Example:**

### Technical Depth (for software/systems content)
- Prefers: Fundamental principles over tools
- Prefers: Generalizable patterns over specific implementations
- Avoid: Syntax-level details without conceptual insight

### Empirical Grounding (for research content)
- Prefers: Studies with clear methodology
- Prefers: Quantitative evidence when available
- Avoid: Anecdotal claims presented as universal

---

## Red Flags (Content to Archive)

Regardless of scores, consider archiving content that:

- **Duplicates existing notes** without adding new perspective
- **Cannot be acted on** (no clear application or next step)
- **Lacks a clear takeaway** after re-reading
- **Feels obligatory rather than interesting** ("I should care about this, but...")
- **Is purely reactive** (rant, complaint, or hot take with no underlying principle)

---

## Working with This Rubric

### Initial Triage (Inbox → Notes)
1. Read the content
2. Score it on the 5 core dimensions
3. If total ≥10/15 and Clarity + Durability ≥4, consider extraction
4. If total ≤6/15, consider archiving after brief review

### Periodic Review (Monthly or Quarterly)
1. Sample 10-15 notes at random
2. Re-evaluate against current rubric
3. Archive notes that no longer meet your standards
4. Update rubric if your criteria have shifted

### Custom Workflows
- Add domain-specific scoring for specialized content types
- Create separate rubrics for different projects or areas
- Adjust thresholds based on vault size and curation intensity

---

## Calibration Notes

*(Use this section to record how your rubric evolves.)*

**Example:**

```
2026-02-18: Initial rubric created
- Using 5 core dimensions (Clarity, Durability, Reusability, Actionability, Uniqueness)
- Threshold: 10/15 for extraction, ≤6/15 for archiving

2026-03-15: Adjusted Uniqueness scoring
- Realized I was keeping too much "common wisdom"
- Raised bar: now requires genuine insight or personal synthesis
- Archived ~20 notes that were just well-known ideas
```

---

## Integration with Skills

This rubric is referenced by:

- **`.agents/review.md`**: For evaluating ideas and drafts
- **`.agents/scoring.md`**: For structured comparison of content
- **`.agents/refactoring.md`**: For deciding what to extract from Inbox/Daily

AI assistants should read this rubric when asked to evaluate, triage, or score content.

---

## Important Reminders

- **This rubric is a tool, not a law**. Override it when intuition says otherwise.
- **Lower scores don't mean "bad"**. They mean "not a fit for long-term storage."
- **Criteria should evolve**. Update this as your thinking changes.
- **Be willing to archive**. Keeping everything dilutes what's valuable.

---

**Your vault is for what you uniquely think and know. Be selective.**
