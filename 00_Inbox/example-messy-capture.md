# Example Inbox Entry

Thinking about trust in markets. Read something about asymmetric information breaking down exchange. Akerlof? The "lemons" problem. When buyers can't verify quality, sellers have incentive to cut corners. Eventually only low-quality goods get sold because buyers assume the worst.

This feels relevant to AI alignment. If humans can't verify what an AI is optimising for, how do we trust it? Similar information asymmetry.

Also: regulation as trust substitute? Mandatory disclosure, warranties, inspection regimes. Does this work for AI? Probably not the same way.

---

**TODO:**
- Look up Akerlof's "Market for Lemons" paper
- Create note on information asymmetry
- Connect to AI safety reading
- Maybe draft essay on trust mechanisms
